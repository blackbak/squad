{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import gensim\n",
    "from text_prep import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_sequence, pad_packed_sequence, pack_padded_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/train-v2.0.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m =0\n",
    "questions = []\n",
    "for i in range(len(data[\"data\"])):\n",
    "    for j in range(len(data[\"data\"][i][\"paragraphs\"])):\n",
    "        for k in range(len(data[\"data\"][i][\"paragraphs\"][j][\"qas\"])):\n",
    "            questions.append(data[\"data\"][i][\"paragraphs\"][j][\"qas\"][k][\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_w2v_model(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_idx = [sentence2idx(model, sentence) for sentence in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu:0\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = gensim2embedding(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, embed_dimension, gru_hidden_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.bi_gru = nn.GRU(input_size=embed_dimension, hidden_size=gru_hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2*gru_hidden_size, 1) # since we want bidirectional\n",
    "        self.activation_fc = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, padded_input, input_lengths):\n",
    "        total_length = padded_input.size(1) #padded_input must be ordered by size\n",
    "        packed_input = pack_padded_sequence(padded_input, input_lengths, batch_first=True)\n",
    "        packed_output, _ = self.bi_gru(packed_input)\n",
    "        gru_output, _ = pad_packed_sequence(packed_output, batch_first=True, total_length = total_length)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_sequence, pad_sequence, pad_packed_sequence, pack_padded_sequence\n",
    "a = torch.tensor([[1,2,3],[1,1,1], [5,5,7]])\n",
    "b = torch.tensor([[4,5,3], [2,2,2]])\n",
    "c = torch.tensor([[6,3,3], [5,5,5]])\n",
    "k = pad_sequence([a, b, c], batch_first=True)\n",
    "m = pack_sequence(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pad_packed_sequence(m, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "First argument of _symbolic_pack_padded_sequence is expected to be a tensor, but got an object of type <class 'tuple'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-a2fa4a1bff7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpack_padded_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# fast pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmight_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\onnx\\__init__.py\u001b[0m in \u001b[0;36mmight_trace\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    143\u001b[0m             raise ValueError('First argument of {} is expected to be a tensor, '\n\u001b[0;32m    144\u001b[0m                              \u001b[1;34m'but got an object of type {}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                              .format(symbolic_fn.__name__, type(first_arg)))\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_is_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_arg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: First argument of _symbolic_pack_padded_sequence is expected to be a tensor, but got an object of type <class 'tuple'>"
     ]
    }
   ],
   "source": [
    "pack_padded_sequence(l, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [1, 1, 1],\n",
       "          [5, 5, 7]],\n",
       " \n",
       "         [[4, 5, 3],\n",
       "          [2, 2, 2],\n",
       "          [0, 0, 0]],\n",
       " \n",
       "         [[6, 3, 3],\n",
       "          [5, 5, 5],\n",
       "          [0, 0, 0]]]), tensor([3, 3, 3]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
